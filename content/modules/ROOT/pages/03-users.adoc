= Creating Users on the Hosted Cluster

One of the primary use cases for a hosted control planes deployment is to provide multitenancy for organizations so that individuals and teams can have their own clusters with dedicated resources that cannot be infringed upon by other users.

Setting up the identity provider for a hosted control plane is different from the standard deployment of OpenShift, because all control plane pods are all managed by the hosting cluster.

In this module you will set up authorization for the hosted cluster by modifing the HostedCluster custom resource on the hosting cluster.

*Goals*

* Set up httpassword authentication two users.
* Enable OAuth for the hosted cluster.
* Test the authentication once the cluster is configured.

In later modules, you will use RHACM policies to grant users additional authority over the hosted cluster.

////
.prepare CLI
----
curl -O https://hcp-cli-download-multicluster-engine.apps.cluster-bb9md.dynamic.redhatworkshops.io/linux/amd64/hcp.tar.gz
mkdir ~/bin
tar -xvzf hcp.tar.gz -C ~/bin/
chmod 755 /home/user/bin/hcp
env -i /home/user/bin/hcp create kubeconfig --name my-hosted-cluster >> my-hosted-cluster.kube
----

.htpasswd-development
----
cat <<'EOF' > .htpasswd-development
admin:$2y$05$dMRkF7f4Wgz/AvBM7UqKm.oucUBbHP3Dai9Qc1k.yKfBIzl3HtP0y
developer:$2y$05$QLjh.UvSYCH2.c7P/CBLMO/gl8f0ywy5b6PPd/k2hPnzEh41xoKiW
EOF
----

.secret
----
oc -n clusters delete secret htpasswd-development
oc -n clusters create secret generic htpasswd-development --from-file=htpasswd=.htpasswd-development
----

.patch oneliner
----
oc -n clusters patch hostedcluster my-hosted-cluster --type=merge --patch='{"spec":{"configuration":{"oauth":{"identityProviders":[{"name":"htpasswd","type":"HTPasswd","htpasswd":{"fileData":{"name": "htpasswd-development"}},"mappingMethod":"claim"}]}}}}'
----

.patch
----
spec:
  configuration:
    oauth:
      identityProviders:
      - htpasswd:
          fileData:
            name: htpasswd-development #secret name
        mappingMethod: claim
        name: htpasswd
        type: HTPasswd
----

.rbac
----
oc adm policy add-cluster-role-to-user cluster-admin admin --kubeconfig my-hosted-cluster.kube
----
////

[[local-auth]]
== Configure Authentication

////
=== Gather the Kubeconfig file to interact with the hosted cluster

. Using the Showroom terminal, SSH over to your bastion host at *{bastion_public_hostname}*.
+
* *User:* {bastion_ssh_user_name}
* *Password:* {bastion_ssh_password}
+
image::users/bastion_login.png[link=self, window=blank, width=100%]

. you are going to use the *hcp* CLI, already installed on the bastion host, to gather the Kubeconfig file from our hosted cluster so you can interact with it via CLI. Copy and paste the following syntax into your console and press Enter.
+
[source,sh,role=execute,subs="attributes"]
----
hcp create kubeconfig --name my-hosted-cluster >> my-hosted-cluster.kube
----
+
image::users/create_kubeconfig.png[link=self, window=blank, width=100%]

. Use the newly created kubeconfig to check the number of nodes in the hosted cluster node pool to confirm it's working as expected.
+
[source,sh,role=execute,subs="attributes"]
----
oc get nodes --kubeconfig my-hosted-cluster.kube
----
+
image::users/oc_get_nodes.png[link=self, window=blank, width=100%]

. With the kubeconfig downloaded and confirmed working you can move onto our next steps. Use the *clear* command to clean up the terminal screen.

=== Create User Credentials

. In your terminal copy and paste the following syntax and press the *Enter* key.
+
[source,sh,role=execute,subs="attributes"]
----
htpasswd -c -B -b myuser.htpasswd myuser R3dH4t1!
----
+
image::users/terminal_create_htpasswd.png[link=self, window=blank, width=100%]

. Use the `cat` command to list the contents of the newly created htpasswd file. Use the syntax below to view the file's contents. It will include our username, and the hashed value of the password you created.
+
[source,sh,role=execute,subs="attributes"]
----
cat myuser.htpasswd
----
+
image::users/cat_htpasswd.png[link=self, window=blank, width=100%]

. Now you can use this value to create a secret in the cluster, which you will need to be able to log in with our own user account. Copy and paste the following syntax, and press the Enter key.
+
[source,sh,role=execute,subs="attributes"]
----
oc create secret generic htpasswd-mysecret --from-file=htpasswd=myuser.htpasswd -n clusters
----
+
image::users/secret_created.png[link=self, window=blank, width=100%]

. With the secret created you can now return to our hosting cluster's OpenShift console and to perform the next steps.
////

=== Create secret for htpasswd authentication

. You will use the very simple htpasswd identity provider to create two users, `admin` and `developer`, each with the password `openshift` and grant them access to the hosted cluster.
.. Create a secret for htpasswd authentication by clicking the *Quick Create* button at the top left of the page.
.. Select *Import YAML*
.. Paste the following syntax and press the *Create* button.
+
[,yaml,role=execute,subs="attributes"]
----
kind: Secret
apiVersion: v1
metadata:
  name: htpasswd-development
  namespace: clusters
data:
  htpasswd: YWRtaW46JDJ5JDA1JGRNUmtGN2Y0V2d6L0F2Qk03VXFLbS5vdWNVQmJIUDNEYWk5UWMxay55S2ZCSXpsM0h0UDB5CmRldmVsb3BlcjokMnkkMDUkUUxqaC5VdlNZQ0gyLmM3UC9DQkxNTy9nbDhmMHl3eTViNlBQZC9rMmhQbnpFaDQxeG9LaVcK
type: Opaque
----
+
image::users/secret_created.png[link=self, window=blank, width=100%]

=== Enable Identity Provider

. To add users to the cluster, you need to change the identity provider configuration in the HostedCluster resource.
.. Starting from the *Overview* page of our hosting cluster *local-cluster*, on the left-side menu click on *Home* and then *API Explorer*.
.. Use the *Filter by kind* box to search for the term `HostedCluster`.
It should return two values, click on the one that shows its version as *v1beta1*.
+
image::users/api_explore_hostedcluster.png[link=self, window=blank, width=100%]

. This will bring up the HostedCluster Resource details where you will add the *htpasswd* identity provider to the HostedCluster.
.. Click on the *Instances* tab to see our *my-hosted-cluster* deployment.
.. Click on the three-dot menu to the right side of our instance, and select *Edit HostedCluster* from the drop-down menu.
+
image::users/edit_hostedcluster.png[link=self, window=blank, width=100%]

. Edit the YAML.
.. Browse to the bottom of the *spec* section and paste in the following syntax to add the *htpasswd* secret as an identity provider.
.. Once complete, click the blue *Save* button.
+
[source,yaml,role=execute]
----
  configuration:
    oauth:
      identityProviders:
      - htpasswd:
          fileData:
            name: htpasswd-development
        mappingMethod: claim
        name: htpasswd
        type: HTPasswd
----
+
image::users/add_auth_hostedcluster.png[link=self, window=blank, width=100%]

. Your oauth pods on the hosted cluster should now be restarting.
Validate their restart.
.. On the left click *Workloads -> Pods*.
.. Change project to `clusters-my-hosted-cluster` with the dropdown box on the top.
.. Filter out only the pods with the name `oauth` and press *Enter*.
.. Notice that the pods have been recently restarted.
+
image::users/oauth_pods_restart.png[link=self, window=blank, width=100%]

. Examine changes to the my-hosted-cluster cluster.
.. Return to *All Clusters -> Infrastructure -> Clusters -> my-hosted-cluster*
.. Scroll down to the *Details* section.
.. Notice that something is now missing.
The credentials for the *kubeadmin* login are now missing.
A different identity provider has been configured.
+
image::users/hosted_cluster_creds_missing.png[link=self, window=blank, width=100%]

[[test-auth]]
== Test Authentication

. Test the changes to the identity provider by logging in to the hosted cluster, *my-hosted-cluster*.
.. Click on the *Console URL* link to launch a new tab with the *my-hosted-cluster* console.
.. Log in with username `admin` and the password `openshift`.
+
NOTE: Notice that there is no option to select htpasswd as our Identity Provider as you would expect. Let's attempt to login anyways and see what happens.
+
image::users/cluster_user_login.png[link=self, window=blank, width=100%]

. When you log in, you are in the *Developer Perspective* which is the default for accounts created with standard user permissions for versions of OpenShift prior to 4.19.
+
image::users/devel_perspective.png[link=self, window=blank, width=100%]


. Navigate to the Administrator Perspective.
.. Click on the *Skip tour* button to bypass and introduction presented to all new users in OpenShift.
.. On the left-side menu, click on the *Developer* menu, and select *Administrator* from the drop-down list.
+
image::users/menu_admin.png[link=self, window=blank, width=100%]

. In the *Administrator* view you will see that you are unable to view practically anything.
This is because you didn't grant the new user account any additional authority over cluster operations.
+
image::users/blank_admin_view.png[link=self, window=blank, width=100%]

In the following module you will use RHACM Governance Policies to grant our new user account additional authority over cluster operations.

== Summary

In this section you performed configuration of the hosted cluster by creating secrets and updating the HostedCluster custom resource on the hosting cluster, which the hosting cluster then sets up on the hosted cluster.
This shows how OpenShift on OpenShfit clusters using hosted control planes can be easily managed from the hosting cluster after being deployed.

In further modules you will learn how to manager more hosted cluster features using custom resources on the hosting cluster, such as HostedCluster, ClusterSets, and Governance Policies.
